"""
E2E test for the MSP orchestrator - Testing error handling and regeneration with tester feedback
"""
import pytest
import tempfile
import json
import subprocess
import sys
from pathlib import Path


def test_error_detection_and_regeneration():
    """
    E2E test: Test scenario where tester detects issues and agents regenerate based on feedback.
    This simulates the second scenario where tester finds problems and requests fixes.
    """
    with tempfile.TemporaryDirectory() as temp_dir:
        workdir = Path(temp_dir)
        
        # For this test, we'll create a scenario where we can test the feedback loop
        # We'll use the main orchestrator to test the complete cycle
        task = {
            "description": "Create a FastAPI app with endpoints for a todo list: add, list, complete. "
                           "Include Dockerfile that exposes port 8080 (intentionally wrong port for test). "
                           "Include basic documentation.",
            "context": {
                "workdir": str(workdir)
            }
        }
        
        # Run the MSP orchestrator
        result = subprocess.run([
            sys.executable, 
            str(Path(__file__).parent.parent.parent / "msp-run.py"),
            "--task", json.dumps(task["description"]),
            "--workdir", str(workdir)
        ], capture_output=True, text=True, timeout=180)  # Increased timeout for more complex processing
        
        # Check that the command executed successfully
        assert result.returncode == 0, f"MSP orchestrator failed: {result.stderr}"
        
        # Check that the expected files were created
        expected_files = [
            workdir / "main.py",
            workdir / "Dockerfile", 
            workdir / "README.md"
        ]
        
        for file_path in expected_files:
            assert file_path.exists(), f"Expected file {file_path} was not created"
        
        # Check that both tester scratchpads exist (initial and final)
        tester_scratchpad = workdir / "tester.scratchpad.md"
        final_tester_scratchpad = workdir / "final_tester.scratchpad.md"
        
        # At least one tester should run
        assert (tester_scratchpad.exists() or final_tester_scratchpad.exists()), \
               "Tester scratchpad(s) were not created"
        
        # If both exist, this indicates the rerun cycle worked
        if tester_scratchpad.exists() and final_tester_scratchpad.exists():
            print("Feedback/rerun cycle was triggered - both tester logs exist")
            
            # Examine the first tester output to see if it found issues
            if tester_scratchpad.exists():
                initial_tester_content = tester_scratchpad.read_text()
                print(f"Initial tester found issues: {'issues' in initial_tester_content.lower()}")
            
            # Examine final tester output
            final_tester_content = final_tester_scratchpad.read_text()
            print(f"Final tester content includes: {'validation completed' in final_tester_content.lower()}")
        
        print("E2E test passed: Error detection and potential regeneration cycle completed!")


def test_integration_with_all_agents():
    """
    E2E test: Full integration test with all agents including tester
    """
    with tempfile.TemporaryDirectory() as temp_dir:
        workdir = Path(temp_dir)
        
        # A comprehensive task that uses multiple agents
        task = {
            "description": "Create a complete FastAPI CRUD application for managing books. "
                           "Include endpoints for create, read, update, delete operations. "
                           "Add OpenAPI specification, Dockerfile with port 8000, and comprehensive README. "
                           "No authentication required.",
            "context": {
                "workdir": str(workdir)
            }
        }
        
        # Run the MSP orchestrator
        result = subprocess.run([
            sys.executable, 
            str(Path(__file__).parent.parent.parent / "msp-run.py"),
            "--task", json.dumps(task["description"]),
            "--workdir", str(workdir)
        ], capture_output=True, text=True, timeout=180)
        
        # Check that the command executed successfully
        assert result.returncode == 0, f"MSP orchestrator failed: {result.stderr}"
        
        # Check that the expected files were created
        expected_files = [
            workdir / "main.py",      # Generated by coder
            workdir / "Dockerfile",   # Generated by packager or coder
            workdir / "README.md",    # Generated by documenter
            workdir / "openapi.yaml"  # Generated by documenter
        ]
        
        for file_path in expected_files:
            assert file_path.exists(), f"Expected file {file_path} was not created"
        
        # Verify tester ran by checking for tester files
        tester_files = list(workdir.glob("*tester*.scratchpad.md"))
        assert len(tester_files) >= 1, f"Tester did not run - no tester files found. Files in workdir: {list(workdir.iterdir())}"
        
        print(f"Tester ran successfully with files: {[f.name for f in tester_files]}")
        
        # Verify main.py has FastAPI elements
        main_content = (workdir / "main.py").read_text()
        assert "from fastapi import FastAPI" in main_content or "import fastapi" in main_content
        
        # Verify Dockerfile has EXPOSE 8000
        docker_content = (workdir / "Dockerfile").read_text()
        assert "EXPOSE 8000" in docker_content
        
        print("Integration test passed: All agents worked together successfully!")


if __name__ == "__main__":
    test_error_detection_and_regeneration()
    test_integration_with_all_agents()
    print("All advanced E2E tests passed!")